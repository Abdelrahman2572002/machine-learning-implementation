{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-JcKVYHuD9h"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# flatten the training data\n",
        "x_train = x_train.reshape(x_train.shape[0], -1)\n",
        "x_test = x_test.reshape(x_test.shape[0], -1)"
      ],
      "metadata": {
        "id": "bEsZMc5muKp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Choose 0 , 1 classes"
      ],
      "metadata": {
        "id": "sRuQK1yo_a-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xx = []\n",
        "yy = []\n",
        "xx_test = []\n",
        "yy_test = []\n",
        "xx = x_train[np.any([y_train == 0,y_train == 1], axis = 0)]\n",
        "yy = y_train[np.any([y_train == 0,y_train == 1], axis = 0)]\n",
        "xx_test = x_test[np.any([y_test == 0,y_test == 1], axis = 0)]\n",
        "yy_test = y_test[np.any([y_test == 0,y_test == 1], axis = 0)]\n",
        "x_train = np.array(xx)\n",
        "y_train = np.array(yy)\n",
        "x_test = np.array(xx_test)\n",
        "y_test = np.array(yy_test)\n",
        "print(x_test.shape, y_test.shape,x_train.shape,y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H-rZQDLuRZB",
        "outputId": "34329eb3-7528-4e7f-aa43-7e7446b84242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2115, 784) (2115,) (12665, 784) (12665,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Standarization"
      ],
      "metadata": {
        "id": "_c_3iwA0-1B9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "0hs2oRnWYfqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test.shape)\n",
        "print(x_val.shape)\n",
        "print(y_test.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "id": "mtBJC5JoY99H",
        "outputId": "c0de9280-c78f-4c45-a29c-d3adf6b897f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1057, 784)\n",
            "(1058, 784)\n",
            "(1057,)\n",
            "(1058,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eps= 1e-8\n",
        "x_train = (x_train - np.mean(x_train,axis=0)) / (np.std(x_train,axis=0)+eps)\n",
        "x_test= (x_test- np.mean(x_train,axis=0)) / (np.std(x_train,axis=0)+eps)\n",
        "x_val = (x_val - np.mean(x_train,axis=0)) / (np.std(x_train,axis=0)+eps)"
      ],
      "metadata": {
        "id": "FZbptmAEw1l3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalization"
      ],
      "metadata": {
        "id": "A563Kh0K--ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    z = np.clip(z, -500, 500)\n",
        "    return (1 / (1 + (np.exp(-z))))"
      ],
      "metadata": {
        "id": "jY8koUf8xxTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_cost(y, y_pred):\n",
        "    y_pred = np.clip(y_pred, 1e-8, 1 - 1e-8) # clip y_pred to avoid dividing by zero\n",
        "    return np.mean((-y * np.log(y_pred)) - ((1 - y) * np.log(1 - y_pred)))"
      ],
      "metadata": {
        "id": "cYKVyUqyv42U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_cost_L1(y, y_pred, w, lambd):\n",
        "    y_pred = np.clip(y_pred, 1e-8, 1 - 1e-8) # clip y_pred to avoid dividing by zero\n",
        "    return np.mean((-y * np.log(y_pred)) - ((1 - y) * np.log(1 - y_pred))) + (lambd * np.sum(np.abs(w)))"
      ],
      "metadata": {
        "id": "urcUORylmvKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Logistic_Regression_L1(w, b, x, y, l, iters,lambd):\n",
        "    n = x.shape[0]\n",
        "    for i in range(iters):\n",
        "        z = np.dot(x, w) + b\n",
        "        phiz = sigmoid(z)\n",
        "        #cost = calculate_cost(y, phiz)\n",
        "        cost = calculate_cost_L1(y, phiz, w, lambd)\n",
        "        #dw = np.dot((phiz - y).T, x) / n\n",
        "        dw = (np.dot(x.T, (phiz - y)) / n) + (lambd * np.sign(w))\n",
        "        db = np.mean((phiz - y))\n",
        "        w = w - l * dw\n",
        "        b = b - l * db\n",
        "    return w, b"
      ],
      "metadata": {
        "id": "Ocp1oLnWx4Wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_validation(w, b, x, y, k, l, iters):\n",
        "    n = x.shape[0]\n",
        "    fold_size = int(n / k)\n",
        "    acc = []\n",
        "    for i in (l):\n",
        "        for f in range(k):\n",
        "            st = f * k\n",
        "            en = st + fold_size\n",
        "            test_idx = range(st, en)\n",
        "            cannot = set(test_idx)\n",
        "            train_idx = [j for j in range(n) if j not in cannot]\n",
        "            cur_x_train = x[train_idx]\n",
        "            cur_y_train = y[train_idx]\n",
        "            cur_x_test = x[test_idx]\n",
        "            cur_y_test = y[test_idx]\n",
        "            nw_w, nw_b = Logistic_Regression_L1(w, b, cur_x_train, cur_y_train, i, iters)\n",
        "            # print(nw_w , nw_b)\n",
        "            cur_acc = get_accuracy(nw_w, nw_b, cur_x_test, cur_y_test)\n",
        "            acc.append(cur_acc)\n",
        "            print(f\"Fold {f + 1}, eta = {i : .3f} , validation accuracy = {cur_acc * 100: .3f} %\")\n",
        "        print('-------------------------------------------------------------')\n",
        "    return np.array(acc)"
      ],
      "metadata": {
        "id": "-rCYLSaV-pBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(w, b, x, y):\n",
        "    y_pred = sigmoid(np.dot(x, w.T) + b)\n",
        "    y_pred = np.round(y_pred)\n",
        "    ret = np.sum(y_pred == y) / int(y.size)\n",
        "    return ret"
      ],
      "metadata": {
        "id": "1pJb66MlJ_Co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing L1 regularization when Î» = [0.01 , 0.9]"
      ],
      "metadata": {
        "id": "q_nE1gfAwgNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with lambda = 0.01\n",
        "init_w = np.zeros(x_train.shape[1])\n",
        "init_b = 0\n",
        "final_w1, final_b1 = Logistic_Regression_L1(init_w, init_b, x_train, y_train, 0.1, 1000,0.01)\n",
        "# Train the model with lambda = 0.9\n",
        "final_w2, final_b2 = Logistic_Regression_L1(init_w, init_b, x_train, y_train, 0.1, 1000,0.1)\n",
        "final_accuracy1 = get_accuracy(final_w1, final_b1, x_val, y_val)\n",
        "final_accuracy2 = get_accuracy(final_w2, final_b2, x_val, y_val)\n",
        "print('final_accuracy =', 100 * final_accuracy1, '%')\n",
        "print('final_accuracy =', 100 * final_accuracy2, '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSmU1Wzo2PC4",
        "outputId": "55eb277f-6c03-4620-f02a-855f73710c8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final_accuracy = 99.7164461247637 %\n",
            "final_accuracy = 99.52741020793951 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Logistic_Regression_mini_batch(w, b, x, y, l, iters, batch_size):\n",
        "    n = x.shape[0]\n",
        "    num_batches = n // batch_size\n",
        "    v_dw = 0\n",
        "    v_db = 0\n",
        "    for i in range(iters):\n",
        "        shuffled_indices = np.random.permutation(n)\n",
        "        x_shuffled = x[shuffled_indices]\n",
        "        y_shuffled = y[shuffled_indices]\n",
        "        for batch in range(num_batches):\n",
        "            batch_start = batch * batch_size\n",
        "            batch_end = batch_start + batch_size\n",
        "            x_batch = x_shuffled[batch_start:batch_end]\n",
        "            y_batch = y_shuffled[batch_start:batch_end]\n",
        "            z = np.dot(x_batch, w.T) + b\n",
        "            phiz = sigmoid(z)\n",
        "            cost = calculate_cost(y_batch, phiz)\n",
        "            v_dw = 0.9 * (np.dot((phiz - y_batch).T, x_batch) / batch_size) + 0.1 * v_dw\n",
        "            w -= l * v_dw / (0.1 ** (i + 1))\n",
        "            v_db = 0.9 * np.sum((phiz - y_batch)) / batch_size + 0.1 * v_db\n",
        "            b -= l * v_db / (0.1 ** (i + 1))\n",
        "            # dw = np.dot((phiz - y_batch).T, x_batch) / batch_size\n",
        "            # db = np.mean(np.sum(phiz - y_batch))\n",
        "            # w = w.T - l * dw\n",
        "            # b = b - l * db\n",
        "            # if u need cost just return it\n",
        "    return w, b"
      ],
      "metadata": {
        "id": "PhViGEcH34al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use the mini batch sizes ( 8 , 500 )"
      ],
      "metadata": {
        "id": "hJonNE7ewOOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "init_w = np.random.randn(x_train.shape[1])\n",
        "init_b = 0\n",
        "\n",
        "# Train the model with batch size = 8\n",
        "final_w1, final_b1 = Logistic_Regression_mini_batch(init_w, init_b, x_train, y_train, 0.1, 10,8)\n",
        "# Train the model with batch size = 6\n",
        "final_w2, final_b2 = Logistic_Regression_mini_batch(init_w, init_b, x_train, y_train, 0.03, 10,6)\n",
        "\n",
        "final_accuracy1 = get_accuracy(final_w1 ,final_b1 , x_val , y_val)\n",
        "final_accuracy2 = get_accuracy(final_w2, final_b2, x_val, y_val)\n",
        "\n",
        "print('final_accuracy =', 100 * final_accuracy1, '%')\n",
        "print('final_accuracy =', 100 * final_accuracy2, '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeVf8bQb9HxY",
        "outputId": "85ffb62b-17b1-4e5d-c82b-942a845d68fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final_accuracy = 99.8109640831758 %\n",
            "final_accuracy = 99.8109640831758 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RMS Prob optimizer\n",
        "\n"
      ],
      "metadata": {
        "id": "OuOizKY_xfDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RMS(x, y, w, b, l, iters, batch_size):\n",
        "    m_samples = x.shape[0]\n",
        "    # cost = []\n",
        "    num_batches = m_samples // batch_size\n",
        "    v_dw = 0\n",
        "    v_db = 0\n",
        "    EPS = 1e-8\n",
        "    for i in range(iters):\n",
        "\n",
        "        shuffled_indices = np.random.permutation(m_samples)\n",
        "        x_shuffled = x[shuffled_indices]\n",
        "        y_shuffled = y[shuffled_indices]\n",
        "\n",
        "        for batch in range(num_batches):\n",
        "            start_batch = batch * batch_size\n",
        "            end_batch = start_batch + batch_size\n",
        "            x_batch = x_shuffled[start_batch:end_batch]\n",
        "            y_batch = y_shuffled[start_batch:end_batch]\n",
        "            z = np.dot(x_batch, w.T) + b\n",
        "            phiz = sigmoid(z)\n",
        "            # cost.append(calculate_cost(y_batch, phiz))\n",
        "\n",
        "            dw = (np.dot((phiz - y_batch).T, x_batch) / batch_size)\n",
        "            db = np.sum((phiz - y_batch)) / batch_size\n",
        "\n",
        "            v_dw = (0.9 * v_dw + 0.1 * dw ** 2)\n",
        "            v_db = (0.9 * v_db + 0.1 * db ** 2)\n",
        "\n",
        "            w -= l * dw / (np.sqrt(v_dw) + EPS)\n",
        "            b -= l * db / (np.sqrt(v_db) + EPS)\n",
        "            # if u need cost just return it\n",
        "    return w, b"
      ],
      "metadata": {
        "id": "ZytM3bVKxdlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_w = np.random.randn(x_train.shape[1])\n",
        "init_b = 0\n",
        "rmsW, rmsB = RMS(x_train, y_train, init_w, init_b, 0.1, 10, 500)\n",
        "final_accuracy_rms1 = get_accuracy(rmsW, rmsB, x_val, y_val)\n",
        "print('final_accuracy =', 100 * final_accuracy_rms1, '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3sFWr9Qx8Bo",
        "outputId": "70447c35-99e9-4e7c-a6a9-5a6140ca0b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final_accuracy = 99.9054820415879 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adam optimizer"
      ],
      "metadata": {
        "id": "cKv2RkIRkgzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adam(x, y, w, b, l, iters, batch_size):\n",
        "    n = x.shape[0]\n",
        "    cost = []\n",
        "    num_batches = n // batch_size\n",
        "    EPS = 1e-8\n",
        "    s_dw = 0\n",
        "    s_db = 0\n",
        "    v_dw = 0\n",
        "    v_db = 0\n",
        "    for i in range(iters):\n",
        "\n",
        "        shuffled_indices = np.random.permutation(n)\n",
        "        x_shuffled = x[shuffled_indices]\n",
        "        y_shuffled = y[shuffled_indices]\n",
        "\n",
        "        for batch in range(num_batches):\n",
        "            start_batch = batch * batch_size\n",
        "            end_batch = start_batch + batch_size\n",
        "            x_batch = x_shuffled[start_batch:end_batch]\n",
        "            y_batch = y_shuffled[start_batch:end_batch]\n",
        "            z = np.dot(x_batch, w.T) + b\n",
        "            phiz = sigmoid(z)\n",
        "            cost.append(calculate_cost(y_batch, phiz))\n",
        "\n",
        "            w_dw = (np.dot((phiz - y_batch).T, x_batch) / batch_size)\n",
        "            b_db = np.sum((phiz - y_batch)) / batch_size\n",
        "\n",
        "            s_dw = (0.9 * s_dw + 0.1 * w_dw ** 2) \n",
        "            s_db = (0.9 * s_db + 0.1 * b_db ** 2) \n",
        "\n",
        "            v_dw = (0.9 * v_dw + 0.1 * w_dw ) \n",
        "            v_db = (0.9 * v_db + 0.1 * b_db ) \n",
        "\n",
        "            w -= l * v_dw / (np.sqrt(s_dw) + EPS)\n",
        "            b -= l * v_db / (np.sqrt(s_db) + EPS)\n",
        "            # if u need cost just return it\n",
        "    return w, b"
      ],
      "metadata": {
        "id": "db4XIfZbkkX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_w = np.random.randn(x_train.shape[1])\n",
        "init_b = 0\n",
        "adamW, adamB = adam(x_train, y_train, init_w, init_b, 0.1, 10, 500)\n",
        "print(adamW , adamB)\n",
        "final_accuracy_adam1 = get_accuracy(adamW, adamB, x_val, y_val)\n",
        "print('final_accuracy =', 100 * final_accuracy_adam1, '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uuCaiusBWZQ",
        "outputId": "beadc49c-6243-4ae2-ab62-3f8106915697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-2.46014041e-01  2.60001434e-01 -1.10143125e-01 -4.25101172e-01\n",
            " -3.37481118e-01  1.81399693e-01  6.63146616e-01  9.27740944e-02\n",
            " -1.28246208e+00 -6.88131138e-01  6.11224962e-01 -5.34808728e-01\n",
            "  9.41440011e-01 -9.04019025e-01 -1.38925870e+00 -2.14955384e-02\n",
            " -6.60785401e-01 -5.67534260e-01  1.14483837e+00  6.82184577e-01\n",
            " -9.45086295e-01 -6.42109327e-01 -1.29517684e-01 -4.12709718e-01\n",
            "  1.81407216e+00 -3.38653577e-01  7.70852003e-01  1.32327904e-01\n",
            " -2.06543517e-01  1.09230450e+00  6.88631747e-01 -3.73859126e-01\n",
            " -5.91675405e-01  7.96784771e-01  1.27565364e+00  8.09750988e-01\n",
            "  1.38946536e+00 -1.10782922e-01 -1.50860563e-01  1.24321744e+00\n",
            "  7.94444464e-01 -1.20673679e+00  6.96103613e+00  2.38584094e+00\n",
            "  3.00849390e-01  2.50151199e-01 -1.61390787e+00  5.72936764e-01\n",
            "  8.84733037e-02  6.26255622e-03 -5.49076503e-01 -4.38624892e-01\n",
            " -2.98285584e-02 -5.78128189e-01 -1.65214968e+00 -1.05126339e-01\n",
            "  2.38616902e-01 -6.15553553e-01  6.76778013e-01  1.99960307e-01\n",
            "  3.28300689e+00 -5.68650688e-01  2.83874724e+00  7.17465280e-01\n",
            "  1.54156833e+00 -7.44548826e-01  9.79401893e+00  1.75111267e+00\n",
            "  2.64266481e-01  6.74611290e-01  2.46377620e+00  9.07939025e+00\n",
            "  1.35942718e+00  2.91629152e+00  2.78288568e+00  3.16373249e+00\n",
            "  8.71850667e+00 -8.19875814e-01  1.22798107e+00 -6.25648231e-01\n",
            " -6.13945682e-01 -7.26179926e-01 -7.05082692e-01 -3.53236749e-01\n",
            "  3.10669558e-01  9.17000861e-01  9.71611933e+00  1.65059837e+00\n",
            "  5.86634199e-01  1.43179329e+00 -1.87965484e-01 -1.45328108e+00\n",
            "  1.05793848e+00  1.63732726e+00  2.84909781e+00  2.15825627e+00\n",
            "  1.64419591e+00  4.89960584e-01  1.91965258e+00  1.60390959e+00\n",
            "  2.53489059e+00  4.33764806e+00  2.88842418e+00  1.64257877e+00\n",
            "  4.52701439e+00  3.50870663e+00  8.62293347e-01  1.28715339e+00\n",
            "  2.03275798e+00 -3.12815255e-01 -9.85743360e-01  7.93699354e-01\n",
            "  6.43619643e-01 -2.48269283e+00  9.01819767e+00  2.68050321e+00\n",
            "  1.39127411e+00 -1.87296335e-01  7.77465864e-01 -1.08814618e+00\n",
            "  1.42243020e+00  1.00922653e+00 -1.06288298e+00  1.21662989e+00\n",
            "  4.30252115e+00  2.99795292e+00 -4.37432371e-01  1.24908179e+00\n",
            "  1.39897453e+00  3.85748081e+00  1.49111964e+00  2.56577381e+00\n",
            "  3.08384206e+00  3.37477024e+00  4.18721729e-01 -2.30725636e+00\n",
            " -6.29296590e-01  1.62676856e+00  2.80612135e-01  1.06778460e-01\n",
            "  5.16517142e-01 -1.29830760e-02  9.30143594e+00  2.60086943e+00\n",
            "  2.03698856e+00  2.00493363e+00  1.02163698e-01 -2.55400818e+00\n",
            " -6.65066416e-01 -1.76912249e+00  7.17425332e-01  1.18530007e+00\n",
            "  1.05671351e+00  1.53846693e+00  9.68136993e-03 -1.24730169e+00\n",
            "  2.36166279e+00  8.55758608e-01 -4.52861331e-01  1.62878654e+00\n",
            " -7.85379871e-02  1.74710438e+00  2.67186835e+00  1.51228951e+00\n",
            "  4.74695823e-01  1.80314969e+00  9.66297476e+00  2.02478190e+00\n",
            " -2.74434297e-01 -8.37586785e-01  1.02993595e+01  1.04983401e+01\n",
            "  1.36843663e+00 -9.03086844e-01 -2.07513642e+00 -1.56874101e+00\n",
            "  2.11096450e-01  3.31662677e-01  3.06936997e-01 -8.78718062e-02\n",
            "  1.52518160e+00  1.03273908e+00 -9.07620580e-02  1.80936869e+00\n",
            " -4.92528985e-01 -1.92027855e-01 -8.44040983e-01 -1.01103658e+00\n",
            "  1.52117857e+00  3.81740650e+00  6.96031232e-01 -1.15794345e+00\n",
            " -2.59571313e-02  1.46722392e+00  1.16502145e+00  1.22335302e+00\n",
            " -4.64296947e-01 -1.69970907e-01  8.64246198e+00  3.68839425e+00\n",
            "  4.20537810e-01  1.26565320e-01 -1.10434965e+00 -1.03119562e+00\n",
            " -8.77409156e-01 -4.91742978e-01 -3.11012743e+00 -2.10759154e+00\n",
            "  6.87666468e-01  1.10662036e+00  2.87719086e+00  1.63883091e+00\n",
            " -3.75656495e+00 -2.91447297e+00 -9.88075695e-01  7.34457480e-01\n",
            " -4.89477055e-02  6.04283950e-01 -8.49711490e-01 -1.37180697e+00\n",
            " -1.73579728e+00  1.07545929e+00  1.63331026e+00  8.44159407e-01\n",
            "  2.79554620e+00 -1.38589311e+00  2.06568637e+00 -1.46949597e+00\n",
            "  1.19984851e+00 -3.23120231e-01 -2.21536669e-02 -1.53595427e+00\n",
            "  1.87248582e+00 -1.68905479e+00 -3.12612501e+00 -7.47357232e-01\n",
            "  2.19917407e+00  2.14971637e+00  1.42989396e+00 -8.47001963e-01\n",
            " -3.53086006e+00 -6.68159370e+00 -1.78047242e+00  2.35290746e-01\n",
            " -8.94715137e-01 -1.80065934e-01  7.05325266e-01 -1.08571960e-01\n",
            " -4.97541362e-01 -1.43119432e+00 -3.78166758e-01 -2.18769656e-01\n",
            "  3.19542094e-02  8.60806126e+00  3.80463188e+00  4.75544964e+00\n",
            "  9.27810279e-01  1.59867629e+00 -6.96876842e-01  6.20837478e-01\n",
            " -2.19462595e-01 -1.71212583e+00 -8.65134571e-01  1.20577707e+00\n",
            " -3.51094999e-01  9.91124356e-01  4.72388352e-01 -1.85519519e+00\n",
            " -1.62409029e+00 -3.98461438e+00 -3.37931280e+00  4.04354994e-02\n",
            " -3.37216016e+00 -2.91488942e+00 -1.90483974e+00 -1.46154707e+00\n",
            "  1.59101927e+00  7.13857743e-01  4.94131409e+00  1.37699694e-01\n",
            " -1.03589556e+00  9.28604154e+00  2.61167562e+00 -3.43912095e-01\n",
            "  1.00359502e-01 -1.54607061e+00 -2.09045937e+00 -1.95267145e+00\n",
            "  7.36420239e-01 -9.22433647e-01  6.27063975e-01 -2.31457312e+00\n",
            " -1.51989528e+00  2.00939650e-02 -1.61996141e+00  2.01646796e+00\n",
            "  9.72660258e-01 -7.74460424e-01 -3.04563181e+00 -1.88111246e+00\n",
            " -6.34713747e-01 -3.85399505e+00 -1.96308244e+00 -1.19345750e+00\n",
            "  2.37295521e+00 -1.92087750e-01  5.25310127e+00  8.02568656e+00\n",
            " -4.59497240e-01  2.20381417e+00  5.99154918e+00  2.15095531e+00\n",
            "  1.27140523e-01 -7.38800206e-01 -1.11373377e+00 -2.19646242e+00\n",
            " -5.33247423e+00 -1.59534810e+00 -3.08176841e+00 -1.89241733e+00\n",
            " -2.36710006e+00  1.29277725e+00  1.37632710e+00  4.96975228e+00\n",
            "  2.32387621e+00 -3.02839287e+00 -6.24362909e+00 -3.32317441e+00\n",
            " -3.92332957e+00 -4.40444015e+00 -2.76038439e+00 -5.10798299e-01\n",
            " -1.72136355e+00 -3.49983021e-01 -1.43744828e+00  7.74203372e+00\n",
            "  1.31449960e+00  2.59338978e+00 -1.70889143e-01 -5.04570317e-01\n",
            "  1.09193209e+00 -7.40323116e-01 -1.53008641e+00 -4.22449069e+00\n",
            " -3.01590420e+00 -2.00517927e+00 -3.16794709e+00 -5.42729560e+00\n",
            " -4.11664846e+00  6.06102532e-01  4.20276842e+00  5.71083316e+00\n",
            "  4.46554998e+00 -2.31747196e+00 -3.76650120e+00 -4.61846188e+00\n",
            " -3.43824493e+00 -5.32364509e+00 -4.11968593e+00 -4.72761929e-01\n",
            "  3.70956176e-01  4.65950080e-01 -2.22871404e+00  9.69272556e+00\n",
            "  9.05615986e+00  4.24309935e-01  3.32039707e+00  4.04871615e-01\n",
            "  2.55766759e-01 -3.58312600e-01 -3.72479297e+00 -4.79054282e+00\n",
            " -3.60571812e+00 -5.70448378e+00 -4.09746426e+00 -6.90043030e+00\n",
            " -1.09102487e+00  5.22163456e+00  6.97254980e+00  6.25202509e+00\n",
            "  2.66906136e+00 -1.16130915e+00 -5.42796611e+00 -4.92390466e+00\n",
            " -3.28795132e+00 -3.51771963e+00 -3.43865456e+00 -2.42045353e+00\n",
            " -8.54793598e-01 -8.48790651e-01  1.27601506e+00 -1.18442231e+00\n",
            " -8.71235628e-01  9.01134085e-01  9.76854177e+00  1.63001582e+00\n",
            "  1.92665596e+00 -2.44902710e+00 -3.38164519e+00 -5.54826789e+00\n",
            " -6.12856008e+00 -2.54923422e+00 -6.91536858e+00 -3.65254920e+00\n",
            "  1.30638341e+00  5.97850295e+00  7.55475956e+00  7.08946602e+00\n",
            "  3.18954166e+00 -3.40316304e+00 -4.12411576e+00 -4.21160633e+00\n",
            " -4.28304372e+00 -5.77735110e+00 -4.30956975e+00 -1.07460251e+00\n",
            " -1.00435239e-01 -1.25656704e+00  8.31299485e+00  8.91915018e-01\n",
            " -9.95798300e-01  5.85734908e-01  9.12715736e+00  2.66522801e-01\n",
            " -1.02098378e-01 -3.14878391e+00 -2.00085871e+00 -6.07388714e+00\n",
            " -4.69104472e+00 -5.60006224e+00 -3.39998532e+00 -1.00757662e+00\n",
            "  3.73647698e+00  6.33489746e+00  7.30749660e+00  5.43925397e+00\n",
            "  1.58270816e+00 -1.11142430e+00 -4.85165244e+00 -3.59987236e+00\n",
            " -3.62388505e+00 -4.60008727e+00 -4.27907225e+00 -1.38136894e+00\n",
            " -1.49072836e+00  1.62094516e-01  6.61021194e+00  2.26607378e-02\n",
            " -1.72487880e+00  9.56102019e+00  7.61621097e+00 -9.00386827e-01\n",
            " -2.75558606e+00 -2.93536305e+00 -3.84602367e+00 -5.52477192e+00\n",
            " -6.09989034e+00 -4.38810519e+00 -3.19372342e+00 -5.82165827e-01\n",
            "  5.69148424e+00  6.03297575e+00  7.63455077e+00  4.08360609e+00\n",
            " -1.99004834e+00 -5.42431129e+00 -2.48650687e+00 -3.84626923e+00\n",
            " -5.22864900e+00 -2.40656795e+00 -3.98877084e+00 -1.27528042e+00\n",
            " -6.15959262e-01  5.49871675e-01  9.36702999e+00  9.74144664e-01\n",
            "  6.66223430e-01  9.38340424e+00  7.90965914e+00 -1.02540148e+00\n",
            "  5.13457572e-01 -1.64483130e+00 -1.54932858e+00 -4.59735034e+00\n",
            " -3.75682470e+00 -6.20557624e+00 -4.76616267e+00  6.91536183e-01\n",
            "  3.95191419e+00  7.20091135e+00  6.19758713e+00  2.01926923e+00\n",
            " -4.61189050e+00 -5.06296965e+00 -4.60253934e+00 -5.38574554e+00\n",
            " -4.42530909e+00 -1.76167718e+00 -4.71160627e+00 -2.35325660e+00\n",
            " -8.41951224e-01  1.66109100e-01  8.75624352e+00  1.27711590e+00\n",
            "  3.24514208e+00  4.23953932e+00  8.93329293e+00  2.12730975e+00\n",
            " -7.25899159e-01 -3.27839022e+00 -3.91369875e+00 -3.28209740e+00\n",
            " -4.30799177e+00 -4.34937596e+00 -4.63242426e+00  1.33242331e+00\n",
            "  3.41233278e+00  4.33006809e+00  1.11059239e-01  7.39607049e-01\n",
            " -4.42635037e+00 -3.30324096e+00 -3.46654682e+00 -2.38811205e+00\n",
            " -1.91547614e+00 -2.53065767e+00  8.04572013e-01 -3.74176000e-01\n",
            " -6.36127096e-01  1.37762243e+00  6.03883996e+00  9.95485633e+00\n",
            "  2.74491501e+00 -8.72635064e-01  1.63315353e+00  1.10417601e+00\n",
            "  1.84663992e-01  4.92435161e-01 -1.41814597e+00 -3.65147619e+00\n",
            " -5.96028382e+00 -4.48475976e+00 -2.07041254e+00 -9.00544734e-01\n",
            "  3.06890293e+00  2.39479234e+00 -1.76001517e+00 -1.47938665e+00\n",
            " -2.81186022e+00 -3.06619761e+00 -2.66712108e+00 -4.70148808e-01\n",
            " -3.35423732e+00 -1.40384270e+00 -3.65549618e-01 -1.08700565e+00\n",
            "  5.91110324e-01  2.48252063e+00  8.19074793e+00  8.20252228e+00\n",
            " -4.69318717e-01 -3.45494580e-01  3.33091607e-01 -4.61326628e-01\n",
            " -5.73772832e-01 -3.66384076e-02  1.59208069e+00 -3.58957401e+00\n",
            " -4.43353882e+00 -2.04383951e+00 -2.61815614e+00 -1.08877442e+00\n",
            " -4.23334884e+00 -1.66200304e+00  4.01775508e-01  3.46242275e-01\n",
            " -2.78276562e-01 -2.00873941e-01 -6.37647274e-01  1.51811250e+00\n",
            "  4.34362581e-01 -1.67066597e+00 -1.38409348e+00 -3.38619724e-01\n",
            " -2.37982000e-01  1.04558283e+00  1.25671769e+00  1.01511452e+01\n",
            "  9.19612452e+00  8.38842913e+00  4.84482111e+00  3.18573038e+00\n",
            " -2.02027499e+00  2.02040771e+00  1.94640868e-01  1.64184977e-01\n",
            " -2.13616372e+00  1.14787413e+00 -4.78897692e-01 -1.70807327e+00\n",
            " -1.58180453e+00 -1.17080552e+00 -2.52904353e+00 -3.98768814e-01\n",
            "  2.54156059e+00  3.73591513e+00  3.39937367e+00  7.86254032e-02\n",
            "  1.46433083e+00  7.96460192e-01  7.44074483e-02  1.20883517e+00\n",
            "  2.31622241e+00  3.10211910e-01  1.68035693e+00  5.76696769e-01\n",
            "  7.36038195e+00  8.37323572e+00  8.68912771e+00 -9.30705256e-01\n",
            "  1.31554777e+00  2.46199765e+00  2.51137108e+00  2.16914224e+00\n",
            "  1.80730917e+00  2.56987758e+00  1.62805256e+00 -2.89377920e+00\n",
            " -1.76403601e+00 -1.13902047e+00 -7.33111493e-01  6.18130624e-01\n",
            "  2.11829059e+00  8.75563846e-01  1.38843445e+00  6.71721201e-01\n",
            "  7.80340691e-01  6.22896262e-01 -1.87623055e+00 -2.04440877e+00\n",
            "  1.41791195e+00  4.77616672e-01  1.49427065e+00  2.39246137e+00\n",
            "  7.31398631e-01 -5.45180820e-01 -1.10950759e+00  3.50731955e+00\n",
            "  4.15083186e+00 -2.51465362e-02 -8.27376031e-01  1.54792008e-01\n",
            "  1.52905140e+00  2.50684985e+00  2.01533021e+00 -1.06110555e+00\n",
            " -9.85931808e-01 -2.25006242e-01  3.62953110e-01  1.75625882e+00\n",
            "  5.52134299e-01  2.62356680e+00  1.07110296e+00 -1.08343729e-01\n",
            " -7.28337621e-01 -1.12108383e+00  1.22986455e+00 -1.34851341e-01\n",
            "  2.18435134e+00  1.43391374e+00  8.47818435e+00  3.24279631e-01\n",
            " -3.73312102e-01 -2.11684914e-01 -8.51288260e-01  9.50691299e+00\n",
            "  1.87401636e-01 -7.86558543e-02 -4.06533945e-01 -1.76378017e-01\n",
            " -1.99258009e+00 -3.53373728e-01  2.53873976e+00  2.23924413e+00\n",
            " -1.51630767e+00  4.38386002e-01 -5.36686562e-01  3.52448278e+00\n",
            "  2.39238796e+00  6.04751044e-01  2.41302683e-01 -5.67892218e-01\n",
            "  1.64954116e+00  2.08801269e+00  6.69565223e-01  1.64924029e+00\n",
            "  1.87804040e+00  3.56290803e+00  9.23394508e+00 -2.00469800e-01\n",
            " -1.35475958e-01  2.02475693e+00  1.50937648e+00  1.56506859e+00\n",
            "  2.78941028e+00  5.19890843e+00 -2.78589781e-01 -6.04489146e-01\n",
            "  9.61031025e-01  5.26491306e-01  1.09686393e+00 -2.82984191e+00\n",
            "  3.10307044e+00 -1.45752287e-01  1.61686183e+00  7.29252680e-01\n",
            " -1.05082915e+00  1.22880778e-01 -1.37813172e-01 -1.49300067e-01\n",
            " -9.64349830e-01  9.88365688e-01  2.19901494e+00  2.59419765e-01\n",
            " -8.49714650e-01  2.65259469e-01  6.81913599e-01 -1.18736654e+00\n",
            "  1.48689107e+00 -1.14701809e+00  1.87362094e-01 -9.02225484e-01\n",
            " -8.63687286e-01  4.39370770e-02  8.24263232e-01 -2.34981384e-01\n",
            "  1.61215935e-01  7.14303539e-02  8.84812845e+00  8.58106728e+00\n",
            "  3.49923125e-01 -6.83792427e-01  3.41019110e+00  4.22218133e+00\n",
            "  6.68668134e+00 -1.00601728e+00  2.22454366e+00  1.22828974e+00\n",
            "  9.07262114e-01 -7.56338241e-01 -7.00355756e-01  2.16939625e+00\n",
            "  1.27000911e-01 -6.06320404e-01  8.80992993e-01  1.11226233e+00\n",
            "  3.35482570e+00  2.15412583e-02  7.79355595e-01  6.00541882e-01\n",
            " -1.86227486e+00 -1.66281313e-01  1.72353916e-01 -5.89486674e-01\n",
            " -7.42348147e-01  1.76716940e+00  1.00674265e+00 -7.20757122e-01\n",
            "  1.27178000e+00 -2.59256135e+00 -3.68569366e-02 -1.34432763e+00\n",
            " -1.34071433e+00 -1.00050996e+00 -9.16865055e-01  1.19589170e-01\n",
            " -2.62768765e-01 -8.40518899e-01 -1.64611672e+00 -4.85817327e-01\n",
            "  7.02874764e-01 -9.30080020e-01 -3.10518117e-01 -5.65198824e-02] -8.630409408566308\n",
            "final_accuracy = 99.9054820415879 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I-eiQ-Wib3os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion\n"
      ],
      "metadata": {
        "id": "x4s_JFSdb4Lv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. In L1 regularization ( lasso ) we see it is prevent overfitting and improve the generalization performance of a model and the weights of the model to be small by adding lambda values to the weights and this will increase the accuracy(preformance)\n"
      ],
      "metadata": {
        "id": "U8IPuEXxfgAY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Mini batch (momentum) use this teqnique to improve the generalization performance of a model by reducing overfitting and deacrease the iterations and help the algorithm escape from the global minima . Smaller batch sizes can help to reduce overfittes.\n"
      ],
      "metadata": {
        "id": "TvPxJd2LfiHx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. RMS will make the greidients more smooth iterations.Get risk of hyper parameter setting (efficency in iterations).It depend on the previous data point"
      ],
      "metadata": {
        "id": "uST37HqyfmDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. adam use mex of RMS and Momentum optimizers. compines the both optimizers and make the performance efficient"
      ],
      "metadata": {
        "id": "XoSjMSYSfpSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After generating diffrent hyper parameters we see that adam optimizer is more efficent and faster."
      ],
      "metadata": {
        "id": "1ZJ4f-OAf51r"
      }
    }
  ]
}